# 03: CoT（Chain of Thought）
# 日本語では「思考の連鎖」と呼ばれることが多い
# LLMに「段階的に」推論を行わせることで、高度な推論タスクを可能にするPrompt Engineering手法です。
# 思考の連鎖（CoT） は人間の推論を反映しており、一貫した一連の論理的推論を通じて体系的な問題解決を促進します。

# https://www.ibm.com/jp-ja/topics/chain-of-thoughts
# 複雑なタスクを最終的な解決に向けた論理的なステップの連続に区切ることで、
# 人間のような推論プロセスをシミュレートするものである。
# この方法論は、人間の知能の基本的な側面を反映しており、
# 問題解決のための構造化されたメカニズムを提供する。
# 言い換えれば、CoTは、精巧な問題を扱いやすい中間的な思考に分解し、
# 順次、決定的な答えへと導くという認知戦略を前提としている。

from ollama_chat import OllamaChatMessage

ollama = OllamaChatMessage(model="llama3.1", second=0.04)


# AI に「空は何色ですか?」と尋ねた場合、AI は「空は青です」など、単純かつ直接的な回答を生成します。
# ただし、CoTプロンプトを使用して空が青い理由を説明するように求められた場合、
# AIは最初に「青」の意味(原色)を定義し、次に大気による他の色の吸収により空が青く見えると推論します。
# この応答は、AI が論理的な議論を構築する能力を示しています。

prompt = """
Q: 3つのリンゴがあり、2つを取ったら、何個残りますか？
A: 一歩ずつ考えてみましょう。
1. 最初に3つのリンゴがあります。
2. 2つのリンゴを取ります。
3. したがって、あなたの手元には2つのリンゴがあります。

---

それでは、次の問題を解いてください。
Q: 5つのリンゴがあり、3つを取りました。その後2つを追加しました。合計で何個のリンゴがありますか？
"""

for chunk in ollama.response_from_message_stream(prompt):
    print(chunk, end="", flush=True)
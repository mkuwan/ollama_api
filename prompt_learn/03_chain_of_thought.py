# 03: CoT（Chain of Thought）
# 日本語では「思考の連鎖」と呼ばれることが多い
# LLMに「段階的に」推論を行わせることで、高度な推論タスクを可能にするPrompt Engineering手法です。
# 思考の連鎖（CoT） は人間の推論を反映しており、一貫した一連の論理的推論を通じて体系的な問題解決を促進します。

# https://www.ibm.com/jp-ja/topics/chain-of-thoughts
# 複雑なタスクを最終的な解決に向けた論理的なステップの連続に区切ることで、
# 人間のような推論プロセスをシミュレートするものである。
# この方法論は、人間の知能の基本的な側面を反映しており、
# 問題解決のための構造化されたメカニズムを提供する。
# 言い換えれば、CoTは、精巧な問題を扱いやすい中間的な思考に分解し、
# 順次、決定的な答えへと導くという認知戦略を前提としている。

from ollama_chat import OllamaChatMessage

ollama = OllamaChatMessage(model="llama3.1", second=0.04)


# AI に「空は何色ですか?」と尋ねた場合、AI は「空は青です」など、単純かつ直接的な回答を生成します。
# ただし、CoTプロンプトを使用して空が青い理由を説明するように求められた場合、
# AIは最初に「青」の意味(原色)を定義し、次に大気による他の色の吸収により空が青く見えると推論します。
# この応答は、AI が論理的な議論を構築する能力を示しています。

# prompt = """
# Q: 3つのリンゴがあり、2つを取ったら、何個残りますか？
# A: 一歩ずつ考えてみましょう。
# 1. 最初に3つのリンゴがあります。
# 2. 2つのリンゴを取ります。
# 3. したがって、あなたの手元には2つのリンゴがあります。

# ---

# それでは、次の問題を解いてください。
# Q: 5つのリンゴがあり、3つを取りました。その後2つを追加しました。合計で何個のリンゴがありますか？
# """

for chunk in ollama.response_from_message_stream(prompt):
    print(chunk, end="", flush=True)


print(f"{"*" * 10} Chain of thought なし {"*" * 10}")
message = "三菱ケミカルの首都はどこですか？"
for chunk in ollama.response_from_message_stream(message):
    print(chunk, end="", flush=True)


message_with_few_shot = f"""
わたしは質問に対して以下のように考えて回答します。
---
Q. 日本の首都はどこですか？
考察: これは日本という名称の国家の首都を尋ねる質問です。
考察: 日本という名称の国が存在するかを考える必要があります。
考察: まず、日本という国は存在するかを考えます。
結果: 日本は存在します。
考察: 日本には首都があるか？
結果: 日本には首都があります。
考察: 日本の首都はどこか？
結果: 日本の首都は東京です。
最終的な回答: 東京
---

Q. クランベリーの首都はどこですか？
考察: これはクランベリーという名称の国家の首都を尋ねる質問です。
考察: クランベリーという名称の国が存在するかを考える必要があります。
考察: まず、クランベリーという国は存在するかを考えます。
結果: クランベリーは存在しません。
最終的な回答: クランベリーという国は存在しないため、首都はありません。

---

Q. トヨタの首都はどこですか？
考察: これはトヨタという名称の国家の首都を尋ねる質問です。
考察: トヨタという名称の国が存在するかを考える必要があります。
考察: まず、トヨタという国は存在するかを考えます。
結果: トヨタという企業は存在しますが、国家としてのトヨタは存在しません。
最終的な回答: トヨタという国は存在しないため、首都はありません。

---
以下の質問に回答してください。
Q. {message}
"""

print()
print(f"{"*" * 10} Chain of thought あり {"*" * 10}")
for chunk in ollama.response_from_message_stream(message_with_few_shot):
    print(chunk, end="", flush=True)